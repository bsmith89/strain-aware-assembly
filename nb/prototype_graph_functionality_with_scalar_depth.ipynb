{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os as _os\n",
    "_os.chdir(_os.environ['PROJECT_ROOT'])\n",
    "print(_os.path.realpath(_os.path.curdir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import graph_tool as gt\n",
    "import graph_tool.draw\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse\n",
    "import scipy as sp\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions for constructing graphs\n",
    "def path_to_edgelist(path):\n",
    "    u = path[0]\n",
    "    edges = []\n",
    "    for v in path[1:]:\n",
    "        edges.append((u, v))\n",
    "        u = v\n",
    "    return edges\n",
    "\n",
    "def new_graph_from_merged_paths(paths, lengths, depths):\n",
    "    g = gt.Graph()\n",
    "    for p in paths:\n",
    "        g.add_edge_list(path_to_edgelist(p))\n",
    "    g.vp['depth'] = g.new_vp('float', depths)\n",
    "    g.vp['length'] = g.new_vp('int', lengths)  \n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_graph(g, **kwargs):\n",
    "    return gt.draw.graph_draw(g, output_size=(300, 300), ink_scale=0.8, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = [\n",
    "    [0, 1, 2, 0],\n",
    "    [3, 4, 5, 3],\n",
    "    [0, 6, 3],\n",
    "    [5, 7, 8, 9, 10, 11],\n",
    "    [9, 12],\n",
    "    [12, 9],\n",
    "]\n",
    "\n",
    "g0 = new_graph_from_merged_paths(paths, depths=np.random.randint(0, 12, size=13), lengths=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g0_pos = draw_graph(g0, vertex_text=g0.vertex_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_graph(g0, pos=g0_pos, vertex_text=g0.vp.length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_graph(g0, pos=g0_pos, vertex_text=g0.vp.depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edge_has_no_siblings(g):\n",
    "    \"Check whether upstream or downstream sibling edges exist for every edge.\"\n",
    "    vs = g.get_vertices()\n",
    "    v_in_degree = g.new_vertex_property('int', vals=g.get_in_degrees(vs))\n",
    "    v_out_degree = g.new_vertex_property('int', vals=g.get_out_degrees(vs))\n",
    "    e_num_in_siblings = gt.edge_endpoint_property(g, v_in_degree, 'target')\n",
    "    e_num_out_siblings = gt.edge_endpoint_property(g, v_out_degree, 'source')\n",
    "    e_has_no_sibling_edges = g.new_edge_property('bool', (e_num_in_siblings.a <= 1) & (e_num_out_siblings.a <= 1))\n",
    "    return e_has_no_sibling_edges\n",
    "\n",
    "def vertex_does_not_have_both_multiple_in_and_multiple_out(g):\n",
    "    vs = g.get_vertices()\n",
    "    return g.new_vertex_property('bool', vals=(\n",
    "        (g.get_in_degrees(vs) <= 1)\n",
    "        | (g.get_out_degrees(vs) <= 1)\n",
    "    ))\n",
    "\n",
    "def label_maximal_unitigs(g):\n",
    "    \"Assign unitig indices to vertices in maximal unitigs.\"\n",
    "    no_sibling_edges = edge_has_no_siblings(g)\n",
    "    # Since any vertex that has both multiple in _and_ multiple out\n",
    "    # edges cannot be part of a larger maximal unitig,\n",
    "    # we could filter out these vertices, at the same time as we\n",
    "    # are filtering out the edges with siblings.\n",
    "    # Potentially this would make the component labeling step\n",
    "    # much faster.\n",
    "    both_sides_branch = vertex_does_not_have_both_multiple_in_and_multiple_out(g)\n",
    "    # TODO: Double check, if this has any implications for the\n",
    "    # \"unitig-ness\" of its neighbors. I _think_\n",
    "    # if we mark edges with siblings before filtering out\n",
    "    # these nodes we should be good.\n",
    "    g_filt = gt.GraphView(\n",
    "        g,\n",
    "        efilt=no_sibling_edges,\n",
    "        vfilt=both_sides_branch,\n",
    "        directed=False\n",
    "    )\n",
    "    # Since we've filtered out the both_sides_branch vertices,\n",
    "    # the labels PropertyMap would include a bunch of the default value (0)\n",
    "    # for these. Instead, we set everything not labeled to -1, now a magic\n",
    "    # value for nodes definitely not in maximal unitigs.\n",
    "    labels = g.new_vertex_property('int', val=-1)\n",
    "    labels, counts = gt.topology.label_components(g_filt, vprop=labels)\n",
    "    return labels, counts, g_filt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_has_no_siblings(g0).a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels, sizes, _g = label_maximal_unitigs(g0)\n",
    "labels.a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_graph(_g, pos=g0_pos, vertex_text=g0.vertex_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_graph(g0, vertex_text=label_maximal_unitigs(g0)[0], pos=g0_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "import operator\n",
    "\n",
    "def maximal_unitigs(g):\n",
    "    \"Generate maximal unitigs as lists of vertices\"\n",
    "    labels, counts, _ = label_maximal_unitigs(g)\n",
    "    # The output *labels* is an array matching vertices to their unitig ids\n",
    "    # while *counts* matches these ids to their sizes.\n",
    "    # Therefore we enumerate the latter to iterate\n",
    "    # through the list of maximal unitigs.\n",
    "    # NOTE: While label_maximal_unitigs does return the\n",
    "    # filtered and undirected graph with sibling edges and multi-in-and-multi-out\n",
    "    # vertices removed, the _original_ graph should be used for the unitig\n",
    "    # construction below.\n",
    "    for i, c in enumerate(counts):\n",
    "        vfilt = (labels.a == i)\n",
    "        assert vfilt.sum() == c\n",
    "        subgraph = gt.GraphView(g, vfilt=vfilt)\n",
    "        unitig = list(subgraph.iter_vertices())\n",
    "        is_cycle = not gt.topology.is_DAG(subgraph)\n",
    "        yield unitig, is_cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unitigs, cycles = list(zip(*maximal_unitigs(g0)))\n",
    "unitigs, cycles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_unitig_neighbors(g, vs):\n",
    "    \"The in and out neighbors of a unitig path.\"\n",
    "    all_ins = reduce(operator.add, map(lambda v: list(g.iter_in_neighbors(v)), vs))\n",
    "    all_outs = reduce(operator.add, map(lambda v: list(g.iter_out_neighbors(v)), vs))\n",
    "    return list(set(all_ins) - set(vs)), list(set(all_outs) - set(vs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_unitig_neighbors(g0, [3, 4, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutate_add_compressed_unitig_vertex(g, vs, is_cycle, drop_vs=False):\n",
    "    v = int(g.add_vertex())\n",
    "    in_neighbors, out_neighbors = list_unitig_neighbors(g, vs)\n",
    "    g.add_edge_list((neighbor, v) for neighbor in in_neighbors)\n",
    "    g.add_edge_list((v, neighbor) for neighbor in out_neighbors)\n",
    "    g.vp.length.a[v] = g.vp.length.a[vs].sum()\n",
    "    g.vp.depth.a[v] = (g.vp.depth.a[vs] * g.vp.length.a[vs]).sum() / g.vp.length.a[v]\n",
    "    if is_cycle:\n",
    "        g.add_edge(v, v)\n",
    "    for old_v in vs:\n",
    "        g.clear_vertex(old_v)\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutate_compress_all_unitigs(g):\n",
    "    unitig_list = maximal_unitigs(g)\n",
    "    all_vs = []\n",
    "    for i, (vs, is_cycle) in enumerate(unitig_list):\n",
    "        # TODO: If len(vs) == 1, this is effectively a no-op and can be dropped.\n",
    "        mutate_add_compressed_unitig_vertex(g, vs, is_cycle)\n",
    "        all_vs.extend(vs)\n",
    "    \n",
    "    g.remove_vertex(set(all_vs), fast=True)\n",
    "    # I think, but am not sure, that the number of nodes removed will always equal the number of edges removed.\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g1 = mutate_compress_all_unitigs(g0.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g1_pos = draw_graph(g1, vertex_text=g1.vertex_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_graph(g1, pos=g1_pos, vertex_text=g1.vp.length)\n",
    "draw_graph(g0, pos=g0_pos, vertex_text=g0.vp.length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_graph(g1, pos=g1_pos, vertex_text=g1.vp.depth)\n",
    "draw_graph(g0, pos=g0_pos, vertex_text=g0.vp.depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "from collections import namedtuple\n",
    "\n",
    "Split = namedtuple('Split', ['u', 'v', 'w', 'l', 'd'])\n",
    "\n",
    "def all_local_paths_as_splits(g, v):\n",
    "    \"Generate all splits, the product of all in-edges crossed with all out-edges.\"\n",
    "    assert v < g.num_vertices(ignore_filter=True)\n",
    "    us = list(g.iter_in_neighbors(v))\n",
    "    ws = list(g.iter_out_neighbors(v))\n",
    "    num_splits = (len(us) * len(ws))\n",
    "    length = g.vp.length.a\n",
    "    depth = g.vp.depth.a\n",
    "    for u, w in product(us, ws):\n",
    "        # NOTE: This splitting function evenly distributes across all paths.\n",
    "        yield Split(u, v, w, length[v], depth[v] / num_splits)\n",
    "\n",
    "def build_tables_from_splits(split_list, start_idx):\n",
    "    \"\"\"Generate edges to and from new, split vertices.\n",
    "    \n",
    "    Note that if splits from adjacent parents are not\n",
    "    reciprocated, no new edge is produced.\n",
    "    \n",
    "    \"\"\"\n",
    "    split_idx = {}\n",
    "    upstream = defaultdict(list)\n",
    "    downstream = defaultdict(list)\n",
    "    length = []\n",
    "    depth = []\n",
    "    for idx, split in enumerate(split_list, start=start_idx):\n",
    "        u, v, w, l, d = split\n",
    "        split_idx[split] = idx\n",
    "        upstream[(v, w)].append(split)\n",
    "        downstream[(u, v)].append(split)\n",
    "        depth.append(d)\n",
    "        length.append(l)\n",
    "    return split_idx, upstream, downstream, np.array(length), np.array(depth)\n",
    "        \n",
    "        \n",
    "def new_edges_from_splits(split_list, split_idx, upstream, downstream, start_idx):\n",
    "    for v, split in enumerate(split_list, start=start_idx):\n",
    "        u_old, v_old, w_old, _, _ = split\n",
    "        v = split_idx[split]\n",
    "        \n",
    "        # Upstream edges\n",
    "        yield (u_old, v, split_idx[split])\n",
    "        for upstream_split in upstream[(u_old, v_old)]:\n",
    "            u = split_idx[upstream_split]\n",
    "            yield (u, v)\n",
    "            \n",
    "        # Downstream edges\n",
    "        yield (v, w_old)\n",
    "        for downstream_split in downstream[(v_old, w_old)]:\n",
    "            w = split_idx[downstream_split]\n",
    "            yield (v, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = [\n",
    "    [3, 4, 5, 0, 1, 2, 6, 7, 8],\n",
    "    [1, 1],\n",
    "]\n",
    "\n",
    "v_split = 1\n",
    "\n",
    "_g = new_graph_from_merged_paths(paths, lengths=1, depths=1)\n",
    "draw_graph(_g, vertex_text=_g.vertex_index)\n",
    "split_list = list(all_local_paths_as_splits(_g, v_split))\n",
    "start_idx = _g.num_vertices(ignore_filter=True)\n",
    "split_idx, upstream, downstream, lengths, depths = build_tables_from_splits(split_list, start_idx=start_idx)\n",
    "edges_to_add = list(set(new_edges_from_splits(split_list, split_idx, upstream, downstream, start_idx)))\n",
    "_g.vertex_properties['_to_drop'] = _g.new_vertex_property('bool', False)\n",
    "_g.add_edge_list(edges_to_add)\n",
    "_g.vp.length.a[np.arange(len(lengths)) + start_idx] = lengths\n",
    "_g.vp.depth.a[np.arange(len(depths)) + start_idx] = depths\n",
    "\n",
    "for k in [v_split]:\n",
    "    _g.vp._to_drop[k] = True\n",
    "_g_pos = draw_graph(_g, vertex_text=_g.vertex_index, vertex_color=_g.vp._to_drop)\n",
    "_g.remove_vertex([v_split])\n",
    "draw_graph(_g, pos=_g_pos, vertex_text=_g.vertex_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_graph(_g, pos=_g_pos, vertex_text=_g.vp.length)\n",
    "draw_graph(_g, pos=_g_pos, vertex_text=_g.vp.depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutate_apply_splits(g, split_list):\n",
    "    \"\"\"Add edges and drop any parent vertices that were split.\n",
    "    \n",
    "    \"\"\"\n",
    "    start_idx = g.num_vertices(ignore_filter=True)\n",
    "    split_idx, upstream, downstream, lengths, depths = (\n",
    "        build_tables_from_splits(split_list, start_idx=start_idx)\n",
    "    )\n",
    "    edges_to_add = list(set(new_edges_from_splits(\n",
    "        split_list, split_idx, upstream, downstream, start_idx\n",
    "    )))\n",
    "    g.add_edge_list(set(edges_to_add))\n",
    "    g.vp.length.a[np.arange(len(lengths)) + start_idx] = lengths\n",
    "    g.vp.depth.a[np.arange(len(depths)) + start_idx] = depths\n",
    "    g.remove_vertex((split.v for split in split_list), fast=True)\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = [\n",
    "    [3, 4, 5, 0, 1, 2, 6, 7, 8],\n",
    "    [1, 1],\n",
    "]\n",
    "\n",
    "_g = new_graph_from_merged_paths(paths, lengths=1, depths=1)\n",
    "g0_pos = draw_graph(_g, vertex_text=_g.vertex_index)\n",
    "\n",
    "split_list = list(all_local_paths_as_splits(_g, 1))\n",
    "print(split_list)\n",
    "mutate_apply_splits(_g, split_list)\n",
    "draw_graph(_g, vertex_text=_g.vp.depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_graph(g1, vertex_text=g1.vertex_index)\n",
    "\n",
    "# Split vertex 1, but drop one of the potential splits\n",
    "# (the one reflecting a linear path with no repeats.)\n",
    "split_list = set(all_local_paths_as_splits(g1, 0)) - set([(1, 0, 3)])\n",
    "print(split_list)\n",
    "g2 = mutate_apply_splits(g1.copy(), split_list=split_list)\n",
    "draw_graph(g2, vertex_text=g2.vp.depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = [\n",
    "    [0, 1, 2, 0],\n",
    "    [2, 2]\n",
    "]\n",
    "_g = new_graph_from_merged_paths(paths, lengths=1, depths=1)\n",
    "split_list = set(all_local_paths_as_splits(_g, 2))\n",
    "_g = mutate_apply_splits(_g, split_list=split_list)\n",
    "split_list = set(all_local_paths_as_splits(_g, 2))\n",
    "_g = mutate_apply_splits(_g, split_list=split_list)\n",
    "\n",
    "draw_graph(_g, vertex_text=_g.vertex_index)\n",
    "\n",
    "split_list = set(all_local_paths_as_splits(_g, 2))\n",
    "_g = mutate_apply_splits(_g, split_list=split_list)\n",
    "# # draw_graph(_g, vertex_text=_g.vertex_index)\n",
    "# split_list = set(all_local_paths_as_splits(_g, 8))\n",
    "# _g = mutate_apply_splits(_g, split_list=split_list)\n",
    "# # draw_graph(_g, vertex_text=_g.vertex_index)\n",
    "# split_list = set(all_local_paths_as_splits(_g, 11))\n",
    "# _g = mutate_apply_splits(_g, split_list=split_list)\n",
    "# # draw_graph(_g, vertex_text=_g.vertex_index)\n",
    "\n",
    "_g = mutate_compress_all_unitigs(_g)\n",
    "# # draw_graph(_g, vertex_text=_g.vertex_index)\n",
    "\n",
    "# split_list = set(all_local_paths_as_splits(_g, 0))\n",
    "# _g = mutate_apply_splits(_g, split_list=split_list)\n",
    "# # draw_graph(_g, vertex_text=_g.vertex_index)\n",
    "\n",
    "draw_graph(_g, vertex_text=_g.vertex_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splits_for_all_vertices(g, split_func):\n",
    "    for v in g.iter_vertices():\n",
    "        yield from split_func(g, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = [\n",
    "    [0, 1, 2, 0],\n",
    "    [2, 2]\n",
    "]\n",
    "_g = new_graph_from_merged_paths(paths, lengths=1, depths=1)\n",
    "draw_graph(_g, vertex_text=_g.vertex_index)\n",
    "split_list = set(splits_for_all_vertices(_g, all_local_paths_as_splits))\n",
    "_g = mutate_apply_splits(_g, split_list=split_list)\n",
    "draw_graph(_g, vertex_text=_g.vertex_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutate_split_all_nodes(g, split_func):\n",
    "    # TODO: Vertices with <= 1 local path will be split into just\n",
    "    # themselves pointing trivially at their neighbors.\n",
    "    # These can be dropped as they are effectively a no-op.\n",
    "    split_list = set(splits_for_all_vertices(g, split_func))\n",
    "    g = mutate_apply_splits(g, split_list=split_list)\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = [\n",
    "    [0, 1, 2, 0],\n",
    "    [0, 0],\n",
    "    [1, 1],\n",
    "    [2, 2],\n",
    "]\n",
    "_g = new_graph_from_merged_paths(paths, lengths=1, depths=1)\n",
    "draw_graph(_g, vertex_text=_g.vertex_index)\n",
    "mutate_split_all_nodes(_g, split_func=all_local_paths_as_splits)\n",
    "draw_graph(_g, vertex_text=_g.vertex_index)\n",
    "mutate_split_all_nodes(_g, split_func=all_local_paths_as_splits)\n",
    "mutate_split_all_nodes(_g, split_func=all_local_paths_as_splits)\n",
    "mutate_split_all_nodes(_g, split_func=all_local_paths_as_splits)\n",
    "mutate_split_all_nodes(_g, split_func=all_local_paths_as_splits)\n",
    "mutate_split_all_nodes(_g, split_func=all_local_paths_as_splits)\n",
    "mutate_split_all_nodes(_g, split_func=all_local_paths_as_splits)\n",
    "%prun mutate_split_all_nodes(_g, split_func=all_local_paths_as_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%prun mutate_compress_all_unitigs(_g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vs = list(range(1_000))\n",
    "\n",
    "paths = [\n",
    "    vs,\n",
    "    list(np.random.choice(vs, 200)),\n",
    "]\n",
    "_g = new_graph_from_merged_paths(paths, lengths=1, depths=1)\n",
    "draw_graph(_g, vertex_text=_g.vertex_index)\n",
    "%prun mutate_compress_all_unitigs(_g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vs = list(range(10_000))\n",
    "\n",
    "paths = (\n",
    "    [\n",
    "        vs,  # A long genome\n",
    "        list(np.random.choice(vs, 500)), # Long-range interconnects\n",
    "        list(np.random.choice(vs, 500)),\n",
    "        list(np.random.choice(vs, 500)),\n",
    "    ]\n",
    "    + [[c, c] for c in np.random.choice(vs, 500)] # Self-loops\n",
    ")\n",
    "_g = new_graph_from_merged_paths(paths, lengths=1, depths=1)\n",
    "print(_g)\n",
    "%prun mutate_compress_all_unitigs(_g)\n",
    "print(_g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%prun mutate_split_all_nodes(_g, split_func=all_local_paths_as_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(_g.vp.length.a)\n",
    "plt.yscale('log')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default",
   "language": "python",
   "name": "default"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}