{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os as _os\n",
    "_os.chdir(_os.environ['PROJECT_ROOT'])\n",
    "print(_os.path.realpath(_os.path.curdir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import graph_tool as gt\n",
    "import graph_tool.draw\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse\n",
    "import scipy as sp\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions for constructing graphs\n",
    "def path_to_edgelist(path):\n",
    "    u = path[0]\n",
    "    edges = []\n",
    "    for v in path[1:]:\n",
    "        edges.append((u, v))\n",
    "        u = v\n",
    "    return edges\n",
    "\n",
    "def new_graph_from_merged_paths(paths, lengths, depths):\n",
    "    g = gt.Graph()\n",
    "    for p in paths:\n",
    "        g.add_edge_list(path_to_edgelist(p))\n",
    "    g.vp['depth'] = g.new_vp('vector<float>')\n",
    "    g.vp.depth.set_2d_array(depths)\n",
    "    g.vp['length'] = g.new_vp('int', lengths)  \n",
    "    g.gp['nsample'] = g.new_gp('int', len(depths))\n",
    "    g.vp['sequence'] = g.new_vp('object', vals=[[k] for k in range(g.num_vertices())])\n",
    "    return g\n",
    "\n",
    "def get_depth_matrix(g, vs=None):\n",
    "    if not vs:\n",
    "        return g.vp.depth.get_2d_array(range(g.gp.nsample))\n",
    "    else:\n",
    "        return np.stack([g.vp.depth[i] for i in vs], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_graph(g, **kwargs):\n",
    "    return gt.draw.graph_draw(g, output_size=(300, 300), ink_scale=0.8, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = [\n",
    "    [0, 1, 2, 0],\n",
    "    [3, 4, 5, 3],\n",
    "    [0, 6, 3],\n",
    "    [5, 7, 8, 9, 10, 11],\n",
    "    [9, 12],\n",
    "    [12, 9],\n",
    "]\n",
    "\n",
    "nsamples = 2\n",
    "nnodes = 13\n",
    "\n",
    "g0 = new_graph_from_merged_paths(\n",
    "    paths,\n",
    "    depths=np.array(np.random.randint(1, 3, size=(nsamples, nnodes))),\n",
    "    lengths=np.array([1] * 13),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_depth_matrix(g0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_seq_str = g0.new_vp('string', list(g0.vp.sequence))\n",
    "\n",
    "g0_pos = draw_graph(g0, vertex_text=_seq_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_graph(g0, pos=g0_pos, vertex_text=g0.vp.length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edge_has_no_siblings(g):\n",
    "    \"Check whether upstream or downstream sibling edges exist for every edge.\"\n",
    "    vs = g.get_vertices()\n",
    "    v_in_degree = g.new_vertex_property('int', vals=g.get_in_degrees(vs))\n",
    "    v_out_degree = g.new_vertex_property('int', vals=g.get_out_degrees(vs))\n",
    "    e_num_in_siblings = gt.edge_endpoint_property(g, v_in_degree, 'target')\n",
    "    e_num_out_siblings = gt.edge_endpoint_property(g, v_out_degree, 'source')\n",
    "    e_has_no_sibling_edges = g.new_edge_property('bool', (e_num_in_siblings.a <= 1) & (e_num_out_siblings.a <= 1))\n",
    "    return e_has_no_sibling_edges\n",
    "\n",
    "def vertex_does_not_have_both_multiple_in_and_multiple_out(g):\n",
    "    vs = g.get_vertices()\n",
    "    return g.new_vertex_property('bool', vals=(\n",
    "        (g.get_in_degrees(vs) <= 1)\n",
    "        | (g.get_out_degrees(vs) <= 1)\n",
    "    ))\n",
    "\n",
    "# def vertex_does_not_have_multiple_in_or_multiple_out(g):\n",
    "#     vs = g.get_vertices()\n",
    "#     return g.new_vertex_property('bool', vals=(\n",
    "#         (g.get_in_degrees(vs) <= 1)\n",
    "#         & (g.get_out_degrees(vs) <= 1)\n",
    "#     ))\n",
    "\n",
    "def label_maximal_unitigs(g):\n",
    "    \"Assign unitig indices to vertices in maximal unitigs.\"\n",
    "    no_sibling_edges = edge_has_no_siblings(g)\n",
    "    # Since any vertex that has both multiple in _and_ multiple out\n",
    "    # edges cannot be part of a larger maximal unitig,\n",
    "    # we could filter out these vertices, at the same time as we\n",
    "    # are filtering out the edges with siblings.\n",
    "    # Potentially this would make the component labeling step\n",
    "    # much faster.\n",
    "    both_sides_branch = vertex_does_not_have_both_multiple_in_and_multiple_out(g)\n",
    "    # TODO: Double check, if this has any implications for the\n",
    "    # \"unitig-ness\" of its neighbors. I _think_\n",
    "    # if we mark edges with siblings before filtering out\n",
    "    # these nodes we should be good.\n",
    "    g_filt = gt.GraphView(\n",
    "        g,\n",
    "        efilt=no_sibling_edges,\n",
    "        vfilt=both_sides_branch,\n",
    "        directed=True\n",
    "    )\n",
    "    g_filt_undirected = gt.GraphView(g_filt, directed=False)\n",
    "    # Since we've filtered out the both_sides_branch vertices,\n",
    "    # the labels PropertyMap would include a bunch of the default value (0)\n",
    "    # for these. Instead, we set everything not labeled to -1, now a magic\n",
    "    # value for nodes definitely not in maximal unitigs.\n",
    "    labels = g.new_vertex_property('int', val=-1)\n",
    "    labels, counts = gt.topology.label_components(g_filt_undirected, vprop=labels)\n",
    "    return labels, counts, g_filt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_has_no_siblings(g0).a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels, sizes, _g = label_maximal_unitigs(g0)\n",
    "print(labels.a)\n",
    "\n",
    "draw_graph(_g, pos=g0_pos, vertex_text=g0.vertex_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_graph(g0, vertex_text=label_maximal_unitigs(g0)[0], pos=g0_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "import operator\n",
    "\n",
    "def maximal_unitigs(g):\n",
    "    \"Generate maximal unitigs as lists of vertices\"\n",
    "    # (1a) Filter edges\n",
    "    # (1b) Label unitigs\n",
    "    labels, counts, g_filt = label_maximal_unitigs(g)\n",
    "    # (2) Find every node in the filtered graph without in-edges (these are the origins)\n",
    "    is_origin = g_filt.new_vp('bool', g_filt.get_in_degrees(g_filt.get_vertices()) == 0)\n",
    "    # (3) Find every node in the filtered graph without out-edges (these are the termina)\n",
    "    is_terminus = g_filt.new_vp('bool', g_filt.get_out_degrees(g_filt.get_vertices()) == 0)\n",
    "    # (4) Iter through the labels.\n",
    "    for i, c in enumerate(counts):\n",
    "        # (a) For each, select the subgraph for that unitig.\n",
    "        vfilt = (labels.a == i)\n",
    "        assert vfilt.sum() == c\n",
    "        subgraph = gt.GraphView(g_filt, vfilt=vfilt)\n",
    "        # (b) Identify the origin a terminus node in the path\n",
    "        origin = gt.GraphView(subgraph, vfilt=is_origin).get_vertices()\n",
    "        terminus = gt.GraphView(subgraph, vfilt=is_terminus).get_vertices()\n",
    "        assert len(origin) == 1\n",
    "        assert len(terminus) == 1\n",
    "        origin, terminus = origin[0], terminus[0]\n",
    "        if origin == terminus:\n",
    "            continue\n",
    "        # (c) Trace the route from the origin to the terminus (`graph_tool.topology.all_paths`)\n",
    "        unitig = list(gt.topology.all_paths(subgraph, origin, terminus))\n",
    "        assert len(unitig) == 1\n",
    "        unitig = unitig[0]\n",
    "        # (d) Ask if, in the unfiltered graph, the terminus connects to the origin. If so, this is a cycle.\n",
    "        is_cycle = bool(g.edge(terminus, origin))\n",
    "        # (e) Yield the route and whether it's a cycle.\n",
    "        yield list(unitig), is_cycle\n",
    "\n",
    "    \n",
    "    \n",
    "#     # The output *labels* is an array matching vertices to their unitig ids\n",
    "#     # while *counts* matches these ids to their sizes.\n",
    "#     # Therefore we enumerate the latter to iterate\n",
    "#     # through the list of maximal unitigs.\n",
    "#     # NOTE: While label_maximal_unitigs does return the\n",
    "#     # filtered and undirected graph with sibling edges and multi-in-and-multi-out\n",
    "#     # vertices removed, the _original_ graph should be used for the unitig\n",
    "#     # construction below.\n",
    "#     for i, c in enumerate(counts):\n",
    "#         vfilt = (labels.a == i)\n",
    "#         assert vfilt.sum() == c\n",
    "#         subgraph = gt.GraphView(g, vfilt=vfilt)\n",
    "#         # TODO: How confident am I that the vs sequence is the correct\n",
    "#         # output sequence? Are the first/last nodes\n",
    "#         # always the overlapping nodes?\n",
    "#         # What happens when it's compressing a cycle?\n",
    "#         # Turns out the order of vs is simply the\n",
    "#         # order of node ids (because they're read\n",
    "#         # off the label array).\n",
    "#         # TODO: To get the correct order I need to\n",
    "#         # consider these nodes on the original\n",
    "#         # graph and find the node that has\n",
    "#         # multiple downstream neighbors.\n",
    "#         # This node is the cycle \"exit\", and\n",
    "#         # should be at the start (and the end)\n",
    "#         # of the sequence list.\n",
    "#         # Also, maybe I can take the most upstream\n",
    "#         # and most downstream node in the\n",
    "#         # unitig (the ones with multiple in and multiple\n",
    "#         # out neighbors), and ask for a path from one\n",
    "#         # of these upstream neighbors to one of the downstream\n",
    "#         # neighbors.\n",
    "#         # The resulting path, with the neighbors trimmed off\n",
    "#         # is the correct vertex order.\n",
    "#         unitig = list(subgraph.iter_vertices())\n",
    "#         is_cycle = not gt.topology.is_DAG(subgraph)\n",
    "#         yield unitig, is_cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_seq_str = g0.new_vp('string', list(_g.vp.sequence))\n",
    "\n",
    "draw_graph(g0, pos=g0_pos, vertex_text=g0.vertex_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unitigs, cycles = list(zip(*maximal_unitigs(g0)))\n",
    "unitigs, cycles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_unitig_neighbors(g, vs):\n",
    "    \"The in and out neighbors of a unitig path.\"\n",
    "    all_ins = reduce(operator.add, map(lambda v: list(g.iter_in_neighbors(v)), vs))\n",
    "    all_outs = reduce(operator.add, map(lambda v: list(g.iter_out_neighbors(v)), vs))\n",
    "    return list(set(all_ins) - set(vs)), list(set(all_outs) - set(vs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_unitig_neighbors(g0, [3, 4, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutate_add_compressed_unitig_vertex(g, vs, is_cycle, drop_vs=False):\n",
    "    v = int(g.add_vertex())\n",
    "    nsample = g.gp.nsample\n",
    "    in_neighbors, out_neighbors = list_unitig_neighbors(g, vs)\n",
    "    g.add_edge_list((neighbor, v) for neighbor in in_neighbors)\n",
    "    g.add_edge_list((v, neighbor) for neighbor in out_neighbors)\n",
    "    g.vp.length.a[v] = g.vp.length.a[vs].sum()\n",
    "    g.vp.sequence[v] = reduce(operator.add, (g.vp.sequence[u] for u in vs), [])\n",
    "    g.vp.depth[v] = (\n",
    "        (\n",
    "            get_depth_matrix(g, vs)\n",
    "            * g.vp.length.a[vs]\n",
    "        ).sum(1) / g.vp.length.a[v]\n",
    "    )\n",
    "    if is_cycle:\n",
    "        g.add_edge(v, v)\n",
    "    for old_v in vs:\n",
    "        g.clear_vertex(old_v)\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutate_compress_all_unitigs(g):\n",
    "    unitig_list = maximal_unitigs(g)\n",
    "    all_vs = []\n",
    "    for i, (vs, is_cycle) in enumerate(unitig_list):\n",
    "        # TODO: If len(vs) == 1, this is effectively a no-op and can be dropped.\n",
    "        mutate_add_compressed_unitig_vertex(g, vs, is_cycle)\n",
    "        all_vs.extend(vs)\n",
    "    \n",
    "    g.remove_vertex(set(all_vs), fast=True)\n",
    "    # I think, but am not sure, that the number of nodes removed will always equal the number of edges removed.\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g1 = mutate_compress_all_unitigs(g0.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_graph(g0, pos=g0_pos, vertex_text=g0.new_vp('string', list(g0.vp.sequence)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g1_pos = draw_graph(g1, vertex_text=g1.vertex_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_graph(g1, pos=g1_pos, vertex_text=g1.new_vp('string', list(g1.vp.sequence)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_depth_matrix(g1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_graph(g1, pos=g1_pos, vertex_text=g1.vp.length)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "draw_graph(g1, pos=g1_pos, vertex_text=g1.vp.depth)\n",
    "draw_graph(g0, pos=g0_pos, vertex_text=g0.vp.depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "from collections import namedtuple\n",
    "\n",
    "# FIXME: Don't work with 'l', and 'd' as elements of the Split namedtuple.\n",
    "Split = namedtuple('Split', ['u', 'v', 'w'])\n",
    "\n",
    "def all_local_paths_as_splits(g, v):\n",
    "    \"Generate all splits, the product of all in-edges crossed with all out-edges.\"\n",
    "    assert v < g.num_vertices(ignore_filter=True)\n",
    "    us = list(g.iter_in_neighbors(v))\n",
    "    ws = list(g.iter_out_neighbors(v))\n",
    "    num_splits = (len(us) * len(ws))\n",
    "    length = g.vp.length[v]\n",
    "    depth = get_depth_matrix(g, vs=[v])\n",
    "    for u, w in product(us, ws):\n",
    "        # NOTE: This (dummy) splitting function evenly distributes across all paths.\n",
    "        # FIXME: Casting depth as a tuple is an ugly hack, necessary\n",
    "        # because I use these Splits as keys into a dictionary.\n",
    "        yield Split(u, v, w), length, depth / num_splits\n",
    "\n",
    "def build_tables_from_splits(split_list, start_idx):\n",
    "    \"\"\"Generate edges to and from new, split vertices.\n",
    "    \n",
    "    Note that if splits from adjacent parents are not\n",
    "    reciprocated, no new edge is produced.\n",
    "    \n",
    "    \"\"\"\n",
    "    split_idx = {}\n",
    "    upstream = defaultdict(list)\n",
    "    downstream = defaultdict(list)\n",
    "    length = []\n",
    "    depth = []\n",
    "    for idx, (split, l, d) in enumerate(split_list, start=start_idx):\n",
    "        u, v, w = split\n",
    "        split_idx[split] = idx\n",
    "        upstream[(v, w)].append(split)\n",
    "        downstream[(u, v)].append(split)\n",
    "        depth.append(d)\n",
    "        length.append(l)\n",
    "    return split_idx, upstream, downstream, np.array(length), np.array(depth)\n",
    "        \n",
    "        \n",
    "def new_edges_from_splits(split_list, split_idx, upstream, downstream, start_idx):\n",
    "    for v, (split, _, _) in enumerate(split_list, start=start_idx):\n",
    "        u_old, v_old, w_old = split\n",
    "        v = split_idx[split]\n",
    "        \n",
    "        # Upstream edges\n",
    "        yield (u_old, v, split_idx[split])\n",
    "        for upstream_split in upstream[(u_old, v_old)]:\n",
    "            u = split_idx[upstream_split]\n",
    "            yield (u, v)\n",
    "            \n",
    "        # Downstream edges\n",
    "        yield (v, w_old)\n",
    "        for downstream_split in downstream[(v_old, w_old)]:\n",
    "            w = split_idx[downstream_split]\n",
    "            yield (v, w)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "paths = [\n",
    "    [3, 4, 5, 0, 1, 2, 6, 7, 8],\n",
    "    [1, 1],\n",
    "]\n",
    "\n",
    "v_split = 1\n",
    "\n",
    "_g = new_graph_from_merged_paths(paths, lengths=1, depths=[[1]])\n",
    "draw_graph(_g, vertex_text=_g.vertex_index)\n",
    "split_list = list(all_local_paths_as_splits(_g, v_split))\n",
    "start_idx = _g.num_vertices(ignore_filter=True)\n",
    "split_idx, upstream, downstream, lengths, depths = build_tables_from_splits(split_list, start_idx=start_idx)\n",
    "edges_to_add = list(set(new_edges_from_splits(split_list, split_idx, upstream, downstream, start_idx)))\n",
    "_g.vertex_properties['_to_drop'] = _g.new_vertex_property('bool', False)\n",
    "_g.add_edge_list(edges_to_add)\n",
    "_g.vp.length.a[np.arange(len(lengths)) + start_idx] = lengths\n",
    "_g.vp.depth.a[np.arange(len(depths)) + start_idx] = depths\n",
    "\n",
    "for k in [v_split]:\n",
    "    _g.vp._to_drop[k] = True\n",
    "_g_pos = draw_graph(_g, vertex_text=_g.vertex_index, vertex_color=_g.vp._to_drop)\n",
    "_g.remove_vertex([v_split])\n",
    "draw_graph(_g, pos=_g_pos, vertex_text=_g.vertex_index)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "draw_graph(_g, pos=_g_pos, vertex_text=_g.vp.length)\n",
    "draw_graph(_g, pos=_g_pos, vertex_text=_g.vp.depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutate_apply_splits(g, split_list):\n",
    "    \"\"\"Add edges and drop any parent vertices that were split.\n",
    "    \n",
    "    \"\"\"\n",
    "    start_idx = g.num_vertices(ignore_filter=True)\n",
    "    split_idx, upstream, downstream, lengths, depths = (\n",
    "        build_tables_from_splits(split_list, start_idx=start_idx)\n",
    "    )\n",
    "    edges_to_add = list(set(new_edges_from_splits(\n",
    "        split_list, split_idx, upstream, downstream, start_idx\n",
    "    )))\n",
    "    g.add_edge_list(set(edges_to_add))\n",
    "    g.vp.length.a[np.arange(len(lengths)) + start_idx] = lengths\n",
    "    new_depth = get_depth_matrix(g)\n",
    "    new_depth[:, np.arange(len(depths)) + start_idx] = depths.T\n",
    "    g.vp.depth.set_2d_array(new_depth)\n",
    "    for split, _, _ in split_list:\n",
    "        g.vp.sequence[split_idx[split]] = g.vp.sequence[split.v]\n",
    "    vertices_to_drop = set(split.v for (split, _, _) in split_list)\n",
    "    g.remove_vertex(vertices_to_drop, fast=True)\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = [\n",
    "    [3, 4, 5, 0, 1, 2, 6, 7, 8],\n",
    "    [1, 1],\n",
    "]\n",
    "\n",
    "nvertices = 9\n",
    "\n",
    "_g = new_graph_from_merged_paths(\n",
    "    paths,\n",
    "    depths=np.array([[1] * nvertices]),\n",
    "    lengths=np.array([1] * nvertices),\n",
    ")\n",
    "_g_pos = draw_graph(_g, vertex_text=_g.vp.depth)\n",
    "\n",
    "split_list = list(all_local_paths_as_splits(_g, 1))\n",
    "print(split_list)\n",
    "mutate_apply_splits(_g, split_list)\n",
    "draw_graph(_g, vertex_text=_g.vp.depth)\n",
    "print(list(_g.vp.sequence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_graph(g1, pos=g1_pos, vertex_text=g1.vertex_index)\n",
    "draw_graph(g1, pos=g1_pos, vertex_text=g1.vp.length)\n",
    "print(get_depth_matrix(g1))\n",
    "\n",
    "# Split vertex 1, but drop one of the potential splits\n",
    "# (the one reflecting a linear path with no repeats.)\n",
    "split_list = list(all_local_paths_as_splits(g1, 0))  #  if split != Split(1, 0, 3)]\n",
    "print(split_list)\n",
    "g2 = mutate_apply_splits(g1.copy(), split_list=split_list)\n",
    "print(get_depth_matrix(g2))\n",
    "draw_graph(g2, vertex_text=g2.vp.length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = [\n",
    "    [0, 1, 2, 0],\n",
    "    [2, 2]\n",
    "]\n",
    "nvertices = 3\n",
    "_g = new_graph_from_merged_paths(\n",
    "    paths,\n",
    "    depths=np.array([[1] * nvertices]),\n",
    "    lengths=np.array([1] * nvertices),\n",
    ")\n",
    "\n",
    "print(get_depth_matrix(_g))\n",
    "print((get_depth_matrix(_g) * _g.vp.length.a).sum())\n",
    "\n",
    "draw_graph(_g, vertex_text=_g.vertex_index)\n",
    "\n",
    "split_list = list(all_local_paths_as_splits(_g, 2))\n",
    "_g = mutate_apply_splits(_g, split_list=split_list)\n",
    "\n",
    "print(get_depth_matrix(_g))\n",
    "print((get_depth_matrix(_g) * _g.vp.length.a).sum())\n",
    "\n",
    "split_list = list(all_local_paths_as_splits(_g, 2))\n",
    "_g = mutate_apply_splits(_g, split_list=split_list)\n",
    "\n",
    "draw_graph(_g, vertex_text=_g.vertex_index)\n",
    "\n",
    "split_list = list(all_local_paths_as_splits(_g, 2))\n",
    "_g = mutate_apply_splits(_g, split_list=split_list)\n",
    "# # draw_graph(_g, vertex_text=_g.vertex_index)\n",
    "# split_list = list(all_local_paths_as_splits(_g, 8))\n",
    "# _g = mutate_apply_splits(_g, split_list=split_list)\n",
    "# # draw_graph(_g, vertex_text=_g.vertex_index)\n",
    "# split_list = list(all_local_paths_as_splits(_g, 11))\n",
    "# _g = mutate_apply_splits(_g, split_list=split_list)\n",
    "# # draw_graph(_g, vertex_text=_g.vertex_index)\n",
    "\n",
    "_g = mutate_compress_all_unitigs(_g)\n",
    "# # draw_graph(_g, vertex_text=_g.vertex_index)\n",
    "\n",
    "# split_list = list(all_local_paths_as_splits(_g, 0))\n",
    "# _g = mutate_apply_splits(_g, split_list=split_list)\n",
    "# # draw_graph(_g, vertex_text=_g.vertex_index)\n",
    "\n",
    "draw_graph(_g, vertex_text=_g.vertex_index)\n",
    "\n",
    "print(get_depth_matrix(_g))\n",
    "print((get_depth_matrix(_g) * _g.vp.length.a).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splits_for_all_vertices(g, split_func):\n",
    "    for v in g.iter_vertices():\n",
    "        yield from split_func(g, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = [\n",
    "    [0, 1, 2, 0],\n",
    "    [2, 2]\n",
    "]\n",
    "nvertices = 3\n",
    "_g = new_graph_from_merged_paths(\n",
    "    paths,\n",
    "    depths=np.array([[1] * nvertices]),\n",
    "    lengths=np.array([1] * nvertices),\n",
    ")\n",
    "\n",
    "draw_graph(_g, vertex_text=_g.vertex_index)\n",
    "split_list = list(splits_for_all_vertices(_g, all_local_paths_as_splits))\n",
    "_g = mutate_apply_splits(_g, split_list=split_list)\n",
    "draw_graph(_g, vertex_text=_g.vertex_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutate_split_all_nodes(g, split_func):\n",
    "    # TODO: Vertices with <= 1 local path will be split into just\n",
    "    # themselves pointing trivially at their neighbors.\n",
    "    # These can be dropped as they are effectively a no-op.\n",
    "    split_list = list(splits_for_all_vertices(g, split_func))\n",
    "    g = mutate_apply_splits(g, split_list=split_list)\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = [\n",
    "    [0, 1, 2, 0],\n",
    "    [0, 0],\n",
    "    [1, 1],\n",
    "    [2, 2],\n",
    "]\n",
    "nvertices = 3\n",
    "_g = new_graph_from_merged_paths(\n",
    "    paths,\n",
    "    depths=np.array([[1] * nvertices]),\n",
    "    lengths=np.array([1] * nvertices),\n",
    ")\n",
    "draw_graph(_g, vertex_text=_g.vertex_index)\n",
    "mutate_split_all_nodes(_g, split_func=all_local_paths_as_splits)\n",
    "draw_graph(_g, vertex_text=_g.vertex_index)\n",
    "mutate_split_all_nodes(_g, split_func=all_local_paths_as_splits)\n",
    "draw_graph(_g, vertex_text=_g.vertex_index)\n",
    "mutate_split_all_nodes(_g, split_func=all_local_paths_as_splits)\n",
    "mutate_split_all_nodes(_g, split_func=all_local_paths_as_splits)\n",
    "mutate_split_all_nodes(_g, split_func=all_local_paths_as_splits)\n",
    "mutate_split_all_nodes(_g, split_func=all_local_paths_as_splits)\n",
    "mutate_split_all_nodes(_g, split_func=all_local_paths_as_splits)\n",
    "%prun mutate_split_all_nodes(_g, split_func=all_local_paths_as_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%prun mutate_compress_all_unitigs(_g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nvertices = 1_000\n",
    "vs = list(range(nvertices))\n",
    "paths = [\n",
    "    vs,\n",
    "    list(np.random.choice(vs, 200)),\n",
    "]\n",
    "\n",
    "_g = new_graph_from_merged_paths(\n",
    "    paths,\n",
    "    depths=np.array([[1] * nvertices]),\n",
    "    lengths=np.array([1] * nvertices),\n",
    ")\n",
    "\n",
    "draw_graph(_g, vertex_text=_g.vertex_index)\n",
    "%prun mutate_compress_all_unitigs(_g)\n",
    "draw_graph(_g, vertex_text=_g.vertex_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nvertices = 10_000\n",
    "vs = list(range(nvertices))\n",
    "paths = (\n",
    "    [\n",
    "        vs,  # A long genome\n",
    "        list(np.random.choice(vs, 500)), # Long-range interconnects\n",
    "        list(np.random.choice(vs, 500)),\n",
    "        list(np.random.choice(vs, 500)),\n",
    "    ]\n",
    "    + [[c, c] for c in np.random.choice(vs, 500)] # Self-loops\n",
    ")\n",
    "_g = new_graph_from_merged_paths(\n",
    "    paths,\n",
    "    depths=np.array([[1] * nvertices]),\n",
    "    lengths=np.array([1] * nvertices),\n",
    ")\n",
    "print(_g)\n",
    "%prun mutate_compress_all_unitigs(_g)\n",
    "print(_g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%prun mutate_split_all_nodes(_g, split_func=all_local_paths_as_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(_g.vp.length.a)\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(get_depth_matrix(_g).squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nvertices = 10_000\n",
    "vs = list(range(nvertices))\n",
    "paths = (\n",
    "    [\n",
    "        vs,  # A long genome\n",
    "        list(np.random.choice(vs, 500)), # Long-range interconnects\n",
    "        list(np.random.choice(vs, 500)),\n",
    "        list(np.random.choice(vs, 500)),\n",
    "    ]\n",
    "    + [[c, c] for c in np.random.choice(vs, 500)] # Self-loops\n",
    ")\n",
    "\n",
    "for nsamples in [100]:\n",
    "    print('\\n', nsamples)\n",
    "    _g = new_graph_from_merged_paths(\n",
    "        paths,\n",
    "        depths=np.array([np.arange(nsamples)]*nvertices).T,\n",
    "        lengths=np.array([1] * nvertices),\n",
    "    )\n",
    "    print(_g)\n",
    "    %time mutate_compress_all_unitigs(_g)\n",
    "    print(_g)\n",
    "    %prun mutate_split_all_nodes(_g, split_func=all_local_paths_as_splits)\n",
    "    print(_g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_graph(g0, pos=g0_pos, vertex_text=g0.vertex_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_in(f):\n",
    "    return np.sum(f, axis=0)\n",
    "\n",
    "def flow_error(f, d):\n",
    "    return d - total_in(f)\n",
    "\n",
    "def frac_contribution(f):\n",
    "    return f / total_in(f)\n",
    "\n",
    "def frac_scaled_error(f, d):\n",
    "    return np.nan_to_num(frac_contribution(f) * flow_error(f, d))\n",
    "\n",
    "def bidir_sse(f, d, weight=1):\n",
    "    sq_flow_errorR = flow_error(f, d) ** 2\n",
    "    sq_flow_errorL = flow_error(f.T, d) ** 2\n",
    "    return (sq_flow_errorR * weight + sq_flow_errorL * weight).sum()\n",
    "\n",
    "def bidir_mean_scaled_error(f, d):\n",
    "    return (frac_scaled_error(f, d) + frac_scaled_error(f.T, d).T) / 2\n",
    "\n",
    "def step(f, d):\n",
    "    return f + bidir_mean_scaled_error(f, d)\n",
    "\n",
    "def estimate_flow(r0, d, epsilon=1e-10, return_trace=False):\n",
    "    r = r0\n",
    "    loss = bidir_sse(r, d)\n",
    "    r_history = [r]\n",
    "    loss_history = [loss]\n",
    "    while True:\n",
    "        r = step(r, d)\n",
    "        loss = bidir_sse(r, d)\n",
    "        delta = loss_history[-1] - loss\n",
    "        loss_history.append(loss)\n",
    "        r_history.append(r)\n",
    "        if delta < epsilon:\n",
    "            if return_trace:\n",
    "                return r_history, loss_history\n",
    "            else:\n",
    "                return r_history[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inverse_total_inflow = sp.sparse.csr_array(sp.sparse.diags(1 / f[1].sum(axis=0)))\n",
    "frac_contribution = sp.sparse.csr_array(gt.spectral.adjacency(_g)) * inverse_total_inflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_total_inflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "i = 2\n",
    "\n",
    "d = _g.vp.depth.get_2d_array([i])\n",
    "a = sp.sparse.csr_array(gt.spectral.adjacency(_g))\n",
    "f_history, loss_history = estimate_flow(a, d, epsilon=1e-10, return_trace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_flow_all_samples(g, samples=None):\n",
    "    if samples is None:\n",
    "        samples = range(g.gp.nsamples)\n",
    "\n",
    "    d = get_depth_matrix(g)\n",
    "    a = sp.sparse.csr_array(gt.spectral.adjacency(g))\n",
    "    flows = []\n",
    "    for i in samples:\n",
    "        f = sp.sparse.csr_array(estimate_flow(a, d[i], epsilon=1e-2))\n",
    "        flows.append(f)\n",
    "    return flows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = estimate_flow_all_samples(_g, samples=[1, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_edge_values_from_matrix(g, x):\n",
    "    ii, jj = g.get_edges().T\n",
    "    return x[jj, ii]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_g.new_edge_property()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_g.new_edge_property('float').a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_g.get_edges([p]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edge_property_from_matrix(g, x):\n",
    "    p = g.new_edge_property('float')\n",
    "    ii, jj = g.get_edges().T\n",
    "    # FIXME: Because edge properties are indexed by some non-existent, edges, it's not clear what to do here...\n",
    "    p.a[:len(ii)] = get_all_edge_values_from_matrix(g, x)\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_matrix_from_edge_property(g, p):\n",
    "    return sp.sparse.csr_array(gt.spectral.adjacency(g, weight=p))\n",
    "\n",
    "x0 = f[1]\n",
    "p = edge_property_from_matrix(_g, x0)\n",
    "x1 = get_matrix_from_edge_property(_g, p)\n",
    "\n",
    "x0.sum(), x1.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_all_edge_values_from_matrix(_g, x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_g.new_edge_property('int', val=1).a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_g.get_edges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(get_all_edge_values_from_matrix(_g, x0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(get_all_edge_values_from_matrix(_g, x1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f[0][a, b].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = f[0].toarray()\n",
    "ii, jj = _g.get_edges().T\n",
    "z[jj, ii].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z[jj, ii]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f[0].toarray().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_g.get_edges()[252]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_g.get_in_edges(146)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_g.get_out_edges(146)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f[1][146, 146]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "((x0.toarray() > 0) == (x1.toarray() > 0)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1#.toarray().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0#.toarray().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_all_edge_values_from_matrix(_g, x0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_all_edge_values_from_matrix(_g, x0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f[1].toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x0 > 0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x1 > 0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x0 > 0.5).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x1 > 0.5).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x1 == 0.75).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x0 == 0.75).toarray().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1.toarray().sum(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_matrix_from_edge_property(_g, p).toarray().sum(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.toarray().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time f[1].toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = _g.new_edge_property('vector<float>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f[1].toarray().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_g.get_edges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default",
   "language": "python",
   "name": "default"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}